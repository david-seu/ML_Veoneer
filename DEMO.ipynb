{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras as k\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = k.models.load_model('model_veoneer.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 114, 114, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 114, 114, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 57, 57, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 57, 57, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 57, 57, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 57, 57, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 28, 28, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 28, 28, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 28, 28, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 14, 14, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 14, 14, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               6422784   \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,519,619\n",
      "Trainable params: 6,518,211\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import math\n",
    "from time import sleep\n",
    "from PIL import Image\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def convert_to_probabilities(predicted_values):\n",
    "    exp_values = [math.exp(val) for val in predicted_values]\n",
    "    sum_exp_values = sum(exp_values)\n",
    "    probabilities = [val / sum_exp_values for val in exp_values]\n",
    "    return probabilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def data2fftimge(data, desired_size=(227,227)):\n",
    "    _,_,_,img = plt.specgram(data.flatten(),NFFT=256,Fs=44100,scale_by_freq=False, noverlap=64)\n",
    "\n",
    "    img_2d = img.make_image(None)[0][...,0:3]\n",
    "\n",
    "    img_resized = Image.fromarray(img_2d).resize(desired_size)\n",
    "\n",
    "    img_tensor = tf.convert_to_tensor(np.array(img_resized))\n",
    "\n",
    "    return img_tensor\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording in 2...\n",
      "Recording in 1...\n",
      "Recording...\n"
     ]
    },
    {
     "ename": "PortAudioError",
     "evalue": "Error querying device -1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPortAudioError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m sleep(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecording...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m val \u001B[38;5;241m=\u001B[39m \u001B[43msd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mduration\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamplerate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m sd\u001B[38;5;241m.\u001B[39mwait()\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecording...Done\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\ML_Veoneer\\venv\\Lib\\site-packages\\sounddevice.py:276\u001B[0m, in \u001B[0;36mrec\u001B[1;34m(frames, samplerate, channels, dtype, out, mapping, blocking, **kwargs)\u001B[0m\n\u001B[0;32m    273\u001B[0m     ctx\u001B[38;5;241m.\u001B[39mread_indata(indata)\n\u001B[0;32m    274\u001B[0m     ctx\u001B[38;5;241m.\u001B[39mcallback_exit()\n\u001B[1;32m--> 276\u001B[0m \u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mInputStream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamplerate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblocking\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\ML_Veoneer\\venv\\Lib\\site-packages\\sounddevice.py:2582\u001B[0m, in \u001B[0;36m_CallbackContext.start_stream\u001B[1;34m(self, StreamClass, samplerate, channels, dtype, callback, blocking, **kwargs)\u001B[0m\n\u001B[0;32m   2579\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstart_stream\u001B[39m(\u001B[38;5;28mself\u001B[39m, StreamClass, samplerate, channels, dtype, callback,\n\u001B[0;32m   2580\u001B[0m                  blocking, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   2581\u001B[0m     stop()  \u001B[38;5;66;03m# Stop previous playback/recording\u001B[39;00m\n\u001B[1;32m-> 2582\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream \u001B[38;5;241m=\u001B[39m \u001B[43mStreamClass\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamplerate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msamplerate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2583\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mchannels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchannels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2584\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2585\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2586\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mfinished_callback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfinished_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2587\u001B[0m \u001B[43m                              \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2588\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m   2589\u001B[0m     \u001B[38;5;28;01mglobal\u001B[39;00m _last_callback\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\ML_Veoneer\\venv\\Lib\\site-packages\\sounddevice.py:1421\u001B[0m, in \u001B[0;36mInputStream.__init__\u001B[1;34m(self, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback)\u001B[0m\n\u001B[0;32m   1391\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, samplerate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, blocksize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1392\u001B[0m              device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, latency\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1393\u001B[0m              extra_settings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, finished_callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1394\u001B[0m              clip_off\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dither_off\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, never_drop_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1395\u001B[0m              prime_output_buffers_using_stream_callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1396\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"PortAudio input stream (using NumPy).\u001B[39;00m\n\u001B[0;32m   1397\u001B[0m \n\u001B[0;32m   1398\u001B[0m \u001B[38;5;124;03m    This has the same methods and attributes as `Stream`, except\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1419\u001B[0m \n\u001B[0;32m   1420\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1421\u001B[0m     \u001B[43m_StreamBase\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkind\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwrap_callback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43marray\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1422\u001B[0m \u001B[43m                         \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_remove_self\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\ML_Veoneer\\venv\\Lib\\site-packages\\sounddevice.py:817\u001B[0m, in \u001B[0;36m_StreamBase.__init__\u001B[1;34m(self, kind, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback, userdata, wrap_callback)\u001B[0m\n\u001B[0;32m    814\u001B[0m         samplerate \u001B[38;5;241m=\u001B[39m isamplerate\n\u001B[0;32m    815\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    816\u001B[0m     parameters, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dtype, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_samplesize, samplerate \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m--> 817\u001B[0m         \u001B[43m_get_stream_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkind\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlatency\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    818\u001B[0m \u001B[43m                               \u001B[49m\u001B[43mextra_settings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamplerate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    819\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_device \u001B[38;5;241m=\u001B[39m parameters\u001B[38;5;241m.\u001B[39mdevice\n\u001B[0;32m    820\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_channels \u001B[38;5;241m=\u001B[39m parameters\u001B[38;5;241m.\u001B[39mchannelCount\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\ML_Veoneer\\venv\\Lib\\site-packages\\sounddevice.py:2660\u001B[0m, in \u001B[0;36m_get_stream_parameters\u001B[1;34m(kind, device, channels, dtype, latency, extra_settings, samplerate)\u001B[0m\n\u001B[0;32m   2657\u001B[0m     samplerate \u001B[38;5;241m=\u001B[39m default\u001B[38;5;241m.\u001B[39msamplerate\n\u001B[0;32m   2659\u001B[0m device \u001B[38;5;241m=\u001B[39m _get_device_id(device, kind, raise_on_error\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m-> 2660\u001B[0m info \u001B[38;5;241m=\u001B[39m \u001B[43mquery_devices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2661\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m channels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2662\u001B[0m     channels \u001B[38;5;241m=\u001B[39m info[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m kind \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_channels\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\ML_Veoneer\\venv\\Lib\\site-packages\\sounddevice.py:569\u001B[0m, in \u001B[0;36mquery_devices\u001B[1;34m(device, kind)\u001B[0m\n\u001B[0;32m    567\u001B[0m info \u001B[38;5;241m=\u001B[39m _lib\u001B[38;5;241m.\u001B[39mPa_GetDeviceInfo(device)\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m info:\n\u001B[1;32m--> 569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PortAudioError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError querying device \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    570\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m info\u001B[38;5;241m.\u001B[39mstructVersion \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    571\u001B[0m name_bytes \u001B[38;5;241m=\u001B[39m _ffi\u001B[38;5;241m.\u001B[39mstring(info\u001B[38;5;241m.\u001B[39mname)\n",
      "\u001B[1;31mPortAudioError\u001B[0m: Error querying device -1"
     ]
    }
   ],
   "source": [
    "fs = 44100\n",
    "duration = 2 # seconds\n",
    "print (\"Recording in 2...\")\n",
    "sleep(1)\n",
    "print (\"Recording in 1...\")\n",
    "sleep(1)\n",
    "print (\"Recording...\")\n",
    "val = sd.rec(frames=fs*duration, samplerate=fs, channels=1)\n",
    "sd.wait()\n",
    "print (\"Recording...Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43mval\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'val' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m image \u001B[38;5;241m=\u001B[39m data2fftimge(\u001B[43mval\u001B[49m)\n\u001B[0;32m      2\u001B[0m image \u001B[38;5;241m=\u001B[39m preprocess_image(image)\n\u001B[0;32m      3\u001B[0m pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(image)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'val' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "image = data2fftimge(val)\n",
    "image = preprocess_image(image)\n",
    "pred = model.predict(image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
